{
    "collab_server" : "",
    "contents" : "##'First step is to create a systematic grid of traps 10x10 in dataframe\nlibrary(secr)\nlibrary(mosaic)\nsetwd(\"~/Google Drive/spatialMR/Rscripts/Simulation\")\ntraplocs<-make.grid(nx=10, ny=10, spacing = .8)\n\n##'Genetically identified individuals (instead of 16-34-299, a letter for simplicity)\nknown<-c(letters, LETTERS, c(\"Aa\", \"Bb\", \"Cc\", \"Dd\", \"Ee\", \"Ff\", \"Gg\",\"Hh\", \"Ii\", \"Jj\"))\nsig<-sqrt(10/pi) #avg homerange 10 sq km (Sollman, Gardner, Belant 2012)\n\n#'Defining 'observation window' in spatstat\nlibrary(spatstat)\ntraprange<-owin(xrange=c(min(traplocs$x)-1,max(traplocs$x)+1),\n                yrange=c(min(traplocs$y)-1,max(traplocs$y)+1))\ntraprange$units$singular<-\"meter\"\ntraprange$units$plural<-\"meters\"\n\n#'Example simple sequential inhibition\n#plot(traprange, main=\"Example Simulated Activity Centers \\n(X), and Trap Locations (o)\")\n#points(traplocs)\n#points(rSSI(r = sig/2, n=length(known), win = traprange, giveup = 10000), pch=\"X\")\n\n\nsim.bear<- function (known, sig, trapsxy, int.g0=.08, behav= -.02, IH=0, sessions=2, redun = 0){\n  library(sp)\n  library(mosaic)\n  library(LaplacesDemon)\n  #Simulating AC's for 15 bears, with inhibition range 'r' defined by homerange radius \n  ACs<-data.frame(AC=rSSI(r = sig/2, n=length(known), win = traprange, giveup = 10000),\n                  ID=known, captured=rep(FALSE,length(known)), IHconstant = abs(rnorm(n = length(known), mean = 0, sd = IH)))\n  BearSamps<-data.frame()\n  \n  \n  for (s in 1:sessions){ #Captures for each session\n    \n    for (b in known){ #Captures for each bear in each session\n      bAC<-as.numeric(filter(ACs, ID==b)[,c(\"AC.x\",\"AC.y\")])\n      #Euclidean distance between AC for this bear and each trap location, and subsequent half-normal capture prob\n      dists<-data.frame(dist=spDistsN1(pts=as.matrix(trapsxy), pt = bAC), trapID=rownames(trapsxy))\n      # intercept capture prob + behavior effect + effect from individual heterogeneity\n      log.g0<- log(int.g0 + behav*filter(ACs, ID==b)[,\"captured\"]) + filter(ACs, ID==b)[,\"IHconstant\"]\n      g0<-exp(log.g0)\n      dists<-mutate(dists, g = g0 * dhalfnorm(scale = sig, x = dist)) \n      \n      for (h in 1:nrow(dists)){ #For each individual trap\n        capProb <- dists$g[h] #Default capture probability\n        if ( rbinom(n=1, size=1, prob=capProb) == 1 ){ ##Coin flip - if captured (evals to 1), add a row to the samps\n          newSamp<-data.frame(type=\"BearMR\", ID = b, Period=s, site=dists$trapID[h]) #first (non-redundant) sample\n          for (v in (1:(rpois(1, redun) + 1))) {BearSamps<-rbind(BearSamps, newSamp)} #if redun is 0, evals to 1, only one samp\n          ACs$captured[which(known==b)] <- TRUE ##Bear is captured, next time the cap prob will change depending on 'behav'\n        }\n        \n      }\n      \n    }\n    \n  }\n  BearSamps$Period<-as.numeric(BearSamps$Period)\n  return(BearSamps)\n}\n\n#' Testing it out - four scenarios. \n#' \n#' i) samples determined solely by half-normal\n#' \n#' ii) detections determined by halfnormal with variable g0 (which is CONSTANT for the simulation for each individual)\n#' \n#' iii) same as i or ii, but including a behavioral effect with captures being more (or less) likely following initial capture\n#' \n#' iv) same as above (i - iii), but with redundant data introduced by way of poisson distribution. \n\n\n#'\n#' i) samples determined solely by half-normal\n#t1<-sim.bear(known = known, sig = sig, int.g0 = .16, trapsxy = traplocs, behav=0, IH=0, sessions=12, redun=0)\n#tally(~ID,data=t1)\n#tally(~Period, data=t1)\n\n#' ii) detections determined by halfnormal with variable g0 (which is CONSTANT for the simulation for each individual)\n#' \n#' IH = .1 creates a random normal value on a normal dist with an sd of .1. That constant becomes an additive contstant for the log function g0.\n#t2<-sim.bear(known = known, sig = sig, int.g0 = .16, trapsxy = traplocs, behav=0, IH=.1, sessions=12, redun=0)\n#tally(~ID,data=t2)\n#tally(~Period, data=t2)\n\n#' iii) same as i or ii, but including a behavioral effect with captures being more (or less) likely following initial capture\n#' \n#' If the bear has been captured previously (ie left a single sample already), the behavioral constant becomes a multiplier for the half-normal distribution of capture probabilties.\n#t3<-sim.bear(known = known, sig = sig, int.g0 = .16, trapsxy = traplocs, behav= -.04, IH=0, sessions=12, redun=0)\n#tally(~ID,data=t3)\n#tally(~Period, data=t3)\n\n#' iv) same as above (i - iii), but with redundant data introduced by way of poisson distribution.\n#' \n#' After a bear is detected at a trap, redundant samples are added by way of a random value taken from a poisson distribution with lambda equal to 'redun'\n#t4<-sim.bear(known = known, sig = sig, int.g0 = .16, trapsxy = traplocs, behav=0, IH=0, sessions=12, redun=1.5)\n#tally(~ID,data=t4)\n#tally(~Period, data=t4)\n\n\n#' Figuring out how to fit to sim data - start by building capture history from samps and detector locations\n\n#first need the names of traps as a col and not as rownames\ntraplocs<-make.grid(nx=10, ny=10, spacing = .8)\ntraplocs[,3]<-rownames(traplocs)\ncolnames(traplocs)<-c(\"x\",\"y\",\"detectorID\")\ntraplocs2<-cbind(traplocs$detectorID, traplocs$x, traplocs$y)\ntraplocs<-as.data.frame(traplocs2)\ncolnames(traplocs)<-c(\"Detector\", \"X\", \"Y\") #Mimicing efford documentation to HOPEFULLY get it to work...\n\ntrapPath<-tempfile(fileext = \".csv\")\nwrite.table(x = traplocs, file = trapPath, sep=\",\", col.names = FALSE, row.names = FALSE) #needed to drop rownames and colnames!\n\nhead(read.csv(trapPath))\n\n#' Now, fit the models in parallel like in original project\nlibrary(doParallel)\nlibrary(foreach)\n\n\nsubsecr.from.samples <- function (samps, trapcsv, modEval, trial, number, subtype, size=200)  { \n  source('~/Google Drive/spatialMR/Rscripts/BearSubsample.R') ##subsampling functions\n  \n  if(trial!=\"t1\" && trial!=\"t2\" && trial!=\"t3\" && trial!=\"t4\"){return(\"invalid trial name: must be t1, t2, t3 or t4 for proper storage of fitted model\")}\n  if(subtype!=\"SimpleRandom\" && subtype!=\"Spread.one\"){return(\"invalid subtype: must be SimpleRandom or Spread.one\")}\n  \n  samps<-BearSubsample(samps, type = subtype, n=size)\n  ##todo: remove the redun samples at this point to make secr actually fit\n    library(secr)\n    fitted<-NULL\n\n    strt<-Sys.time()\n    patht0<-tempfile(fileext = \".csv\")\n    write.table(samps, file=patht0, sep = \",\") \n    \n    t0caphist<-read.capthist(captfile = patht0, trapfile = trapcsv, detector = 'proximity')\n    try({fitted<-secr.fit(t0caphist, model = modEval, buffer = 10, trace = FALSE, CL=TRUE, detectfn = 0)})\n    if(!is.null(fitted)){outcome<-TRUE} else{outcome<-FALSE; print(\"Model fit failed.\")}\n    fitted$timeElapsed<-Sys.time() - strt\n    fitted$samples<-samps\n    \n    #now save the object in some logical way as RDS\n    modEval<-Reduce(paste, deparse(modEval))\n    modelPathName<-gsub(pattern = \"~\", replacement = \"tilde\" , x = modEval)\n    pathRDS<-paste(\"~/Google Drive/spatialMR/data/SimulationData/\", trial, \"/\" , modelPathName ,\"/\", subtype, \"/\", number, \".rds\", collapse=\"\", sep=\"\")\n    saveRDS(fitted, file = pathRDS)\n}\n\n##Figure out what the last one was, start off there (so I don't have to do it manually)\nstarts<-data.frame()\nfor(j in c(\"t1\", \"t2\", \"t3\", \"t4\")){\n    for (k in c(\"g0 tilde b\", \"g0 tilde b + t\", \"g0 tilde t\")){\n          for (l in c(\"SimpleRandom\", \"Spread.one\")){\n            path<-paste(\"~/Google Drive/spatialMR/data/SimulationData/\", j, \"/\", k, \"/\", l, sep=\"\", collapse=\"\")\n            files<-list.files(path)\n            whichDesktop<-which(files==\"desktop.ini\")\n            files<-files[-whichDesktop]\n            print(path)\n            if (length(files)==0){\n              newLine<-data.frame(trial=j,model=k,subtype=l, startno=10001)\n            }\n            else{\n              last<-strsplit(max(files), \"\")[[1]][1:5]\n              last<-as.numeric(paste(last, sep=\"\", collapse=\"\"))\n              newLine<-data.frame(trial=j,model=k,subtype=l, startno=last+1)\n            }\n            starts<-rbind(starts, newLine)\n          }\n    }\n}\ncolnames(starts)<-c(\"trial\", \"model\", \"subtype\", \"startno\")\n##Start up the subsampling and secr fitting, with the new start numbers\n##Todo: make sure this works then try doParallel\ntraplocs<-make.grid(nx=10, ny=10, spacing = .8)\n\n#setup parallel backend to use all processors - note that this is not generally recommended for\n#computers that are actually in use, but since this was run primarily on a server and/or broken\n#laptop, I opted to use all cores, because I didn't need any cores to run other tasks. \ncl<-makeCluster(detectCores())\nregisterDoParallel(cl)\n\nbear.init<-function(){\n\nforeach (l=c(\"SimpleRandom\", \"Spread.one\")) %dopar% {\n  source('~/Google Drive/spatialMR/Rscripts/Simulation/Spatial.R')\n    for (j in c(\"t1\")) {\n      for (k in c(\"g0 ~ b\")) {\n        library(spatstat)\n        library(secr)\n        library(LaplacesDemon)\n        library(mosaic)\n        library(sp)\n        library(foreach)\n      \n        hairsamps<-sim.bear(known = known, sig = sig, int.g0 = .16, trapsxy = traplocs, behav=0, IH=0, sessions=12, redun=0)\n        notilde<-gsub(pattern = \"~\", replacement = \"tilde\" , x = k)\n        startno<-filter(starts, trial==j, model==notilde, subtype==l)[,4]\n        subsecr.from.samples(samps = hairsamps, trapcsv = trapPath, modEval = as.formula(k), trial = j, number = startno, subtype = l, size = 200)\n      }\n    }    \n  }\n}\n\n#for(p in 1:10000){bear.init()}",
    "created" : 1474910414566.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "887543009",
    "id" : "D36E1F65",
    "lastKnownWriteTime" : 1474910194,
    "last_content_update" : 1474910194,
    "path" : "~/Google Drive/spatialMR/Rscripts/Simulation/Spatial.R",
    "project_path" : "Simulation/Spatial.R",
    "properties" : {
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}